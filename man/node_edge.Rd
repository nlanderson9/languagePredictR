% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/node_edge.R
\name{node_edge}
\alias{node_edge}
\title{Create Node-Edge Table}
\usage{
node_edge(
  input,
  maxDist = 4,
  removeStopwords = FALSE,
  binaryPenalty = FALSE,
  showProgress = TRUE
)
}
\arguments{
\item{input}{Either a vector of strings, or a model generated by the \code{\link{language_model}} function}

\item{maxDist}{The maximum distance to consider two words being co-occurent. Default is 4 (i.e. for "I went to the store," "I" and "store" are 4 words apart)}

\item{removeStopwords}{If TRUE, words in \code{quanteda} \code{stopwords} function are excluded from analysis. Defaults to FALSE.}

\item{binaryPenalty}{If TRUE, edge weights for each word pair will be penalized according to the edge weight of that word pair in the opposing text dataset. See Details.}

\item{showProgress}{IF TRUE, progress bars are displayed. Defaults to TRUE.}
}
\value{
A dataframe with node and edge weight information, along with occurence counts. See "Details."
}
\description{
Creates a table of nodes and edges based on a language corpus. Edge weights represent the average distance between two words, corrected by their frequency of appearance.
}
\details{
This function quantifies the relationship between words in the provided text. \cr
It computes a measure of inverse average distance between word pairs, and then multiples that by a Dice coefficient (to control for frequency of occurrence and co-occurence of words) \cr
Specifically, the formula used is:
\deqn{weight = \frac{1}{\bar{D}}*\frac{2*|X \cap Y|}{|X| + |Y|}}
where: \cr
\eqn{\bar{D}} = mean distance between word X and word Y \cr
\eqn{|X \cap Y|} = number of co-occurences of word X and word Y \cr
\eqn{|X|} = number of occurences of word X across all pairs \cr
\eqn{|Y|} = number of occurences of word Y across all pairs \cr
\cr
If a model predicting a binary outcome variable is provided (and thus two separate word networks will be plotted, for the text corresponding to each variable),\cr
the \code{binaryPenalty} argument is available. This penalizes the edge weights for a given network by the strength of the edge weight for the same word pair in the\cr
opposing network. So if the word pair "my house" appears in the text for Outcome 0 with a weight of .33, and it also appears in the text for Outcome 1 with a weight\cr
of .21, applying the \code{binaryPenalty} would result in weights of \code{.33*(1 - .21)} and \code{.21*(1 - .33)}. If a word only appears in one Outcome text, its\cr
weight is unmodified.
\cr\cr
The output dataframe will contain the following columns: \cr
-**first** and **second** columns: the nodes specifying the two words of the pair \cr
-**inverse_mean_distance**: the mean distance between the word pair, computed as an inverse to give greater weight to words that are closer together (\eqn{\frac{1}{\bar{D}}}) \cr
-**cooc_count**: the number of co-occurences of the **first** and **second** words (\eqn{|X \cap Y|}) \cr
-**first_count**: the number of times the **first** word appears in a pair (\eqn{|X|}) \cr
-**second_count**: the number of times the **first** word appears in a pair (\eqn{|Y|}) \cr
-**weight**: the final weight, calculated as above
}
\examples{
\dontrun{
movie_review_data1$cleanText = clean_text(movie_review_data1$text)

# Using language to predict "Positive" vs. "Negative" reviews
movie_model_valence = language_model(movie_review_data1,
                                     outcomeVariableColumnName = "valence",
                                     outcomeVariableType = "binary",
                                     textColumnName = "cleanText")

node_edge_table = node_edge(movie_model_valence)
}

}
